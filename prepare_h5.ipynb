{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6522fe4",
   "metadata": {},
   "source": [
    "# HDF5 Dataset Builder\n",
    "\n",
    "Use this notebook only to create HDF5 datasets from raw audio. Training, evaluation, and inference remain in the main notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00314fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ data_root: c:\\Users\\pczec\\Desktop\\Studia\\SEM5\\IML\\IML-PW\\Recordings\n",
      "ðŸ“ output_dir: c:\\Users\\pczec\\Desktop\\Studia\\SEM5\\IML\\IML-PW\\outputs\n"
     ]
    }
   ],
   "source": [
    "# Imports and configuration\n",
    "\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths (edit these)\n",
    "BASE_DIR = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "# Notebook is inside IML-PW, so use local folders\n",
    "data_root = BASE_DIR / \"Recordings\"\n",
    "output_dir = BASE_DIR / \"outputs\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not data_root.exists():\n",
    "    alt = BASE_DIR.parent / \"IML-PW\" / \"Recordings\"\n",
    "    if alt.exists():\n",
    "        print(f\"âš ï¸ Using fallback data_root: {alt}\")\n",
    "        data_root = alt\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Recordings folder not found. Checked: {data_root} and {alt}\")\n",
    "\n",
    "print(f\"ðŸ“ data_root: {data_root}\")\n",
    "print(f\"ðŸ“ output_dir: {output_dir}\")\n",
    "\n",
    "# Audio / feature params\n",
    "sr = 16000\n",
    "n_mels = 64\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "chunk_duration = 3.0  # seconds\n",
    "\n",
    "# Augmentation toggles\n",
    "WITH_NOISE = True\n",
    "WITH_SPEED = True\n",
    "WITH_VTLP = False\n",
    "WITH_SPECTRAL = True\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "SUPPORTED_EXTS = (\".wav\", \".mp3\", \".m4a\", \".wma\")\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ac63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# INFERENCE-COMPATIBLE PREPROCESSING CLASS\n",
    "# ==========================================================\n",
    "from scipy.signal import butter, lfilter\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "class AudioPreprocessor:\n",
    "    \"\"\"Lightweight preprocessing pipeline.\"\"\"\n",
    "    def __init__(self, sr=16000, n_mels=64, n_fft=2048, hop_length=512,\n",
    "                 chunk_duration=3.0, remove_silence=True, normalize=True,\n",
    "                 lowcut=None, highcut=None, filter_order=4):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.chunk_duration = chunk_duration\n",
    "        self.remove_silence = remove_silence\n",
    "        self.normalize = normalize\n",
    "        self.lowcut = lowcut\n",
    "        self.highcut = highcut\n",
    "        self.filter_order = filter_order\n",
    "\n",
    "    def load_audio(self, path):\n",
    "        \"\"\"Load and resample audio.\"\"\"\n",
    "        audio = AudioSegment.from_file(path)\n",
    "        if audio.channels > 1:\n",
    "            audio = audio.set_channels(1)\n",
    "\n",
    "        samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "        samples /= (1 << (8 * audio.sample_width - 1))\n",
    "\n",
    "        if audio.frame_rate != self.sr:\n",
    "            samples = librosa.resample(samples, orig_sr=audio.frame_rate, target_sr=self.sr)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def trim_silence(self, samples, top_db=30):\n",
    "        \"\"\"Remove silence from audio.\"\"\"\n",
    "        non_silent, _ = librosa.effects.trim(samples, top_db=top_db)\n",
    "        return non_silent\n",
    "\n",
    "    def normalize_volume(self, samples):\n",
    "        \"\"\"Normalize audio volume.\"\"\"\n",
    "        max_val = np.max(np.abs(samples)) + 1e-9\n",
    "        return samples / max_val\n",
    "\n",
    "    def apply_filter(self, samples):\n",
    "        \"\"\"Apply Butterworth filter.\"\"\"\n",
    "        if not self.lowcut and not self.highcut:\n",
    "            return samples\n",
    "\n",
    "        nyq = 0.5 * self.sr\n",
    "        if self.lowcut and self.highcut:\n",
    "            b, a = butter(self.filter_order, [self.lowcut / nyq, self.highcut / nyq], btype=\"band\")\n",
    "        elif self.lowcut:\n",
    "            b, a = butter(self.filter_order, self.lowcut / nyq, btype=\"high\")\n",
    "        else:\n",
    "            b, a = butter(self.filter_order, self.highcut / nyq, btype=\"low\")\n",
    "\n",
    "        return lfilter(b, a, samples)\n",
    "\n",
    "    def chunk_audio(self, samples):\n",
    "        \"\"\"Split audio into fixed-length chunks.\"\"\"\n",
    "        chunk_len = int(self.chunk_duration * self.sr)\n",
    "        chunks = []\n",
    "\n",
    "        for i in range(0, len(samples), chunk_len):\n",
    "            chunk = samples[i:i + chunk_len]\n",
    "            if len(chunk) < chunk_len:\n",
    "                pad = np.zeros(chunk_len, dtype=samples.dtype)\n",
    "                pad[:len(chunk)] = chunk\n",
    "                chunk = pad\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def to_logmel(self, samples):\n",
    "        \"\"\"Convert audio to log-mel spectrogram.\"\"\"\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=samples, sr=self.sr, n_mels=self.n_mels,\n",
    "            n_fft=self.n_fft, hop_length=self.hop_length\n",
    "        )\n",
    "        logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "        return logmel.astype(np.float32)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Return configuration dict.\"\"\"\n",
    "        return {\n",
    "            \"sr\": self.sr,\n",
    "            \"n_mels\": self.n_mels,\n",
    "            \"n_fft\": self.n_fft,\n",
    "            \"hop_length\": self.hop_length,\n",
    "            \"chunk_duration\": self.chunk_duration,\n",
    "            \"remove_silence\": self.remove_silence,\n",
    "            \"normalize\": self.normalize,\n",
    "            \"lowcut\": self.lowcut,\n",
    "            \"highcut\": self.highcut,\n",
    "            \"filter_order\": self.filter_order\n",
    "        }\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# AUGMENTATION FUNCTIONS\n",
    "# ==========================================================\n",
    "def add_ambient_noise(samples, noise_factor=0.005):\n",
    "    \"\"\"Add Gaussian noise.\"\"\"\n",
    "    noise = np.random.randn(len(samples)) * noise_factor\n",
    "    return samples + noise\n",
    "\n",
    "\n",
    "def speed_perturbation(samples, sr, speed_factor=1.0):\n",
    "    \"\"\"Apply time stretching.\"\"\"\n",
    "    return librosa.effects.time_stretch(samples, rate=speed_factor)\n",
    "\n",
    "\n",
    "def spectral_augmentation(logmel, freq_mask_param=10, time_mask_param=20, n_masks=2):\n",
    "    \"\"\"Apply SpecAugment-style masking.\"\"\"\n",
    "    augmented = logmel.copy()\n",
    "    n_mels, n_frames = augmented.shape\n",
    "\n",
    "    for _ in range(n_masks):\n",
    "        f = np.random.randint(0, min(freq_mask_param, n_mels))\n",
    "        f0 = np.random.randint(0, max(1, n_mels - f))\n",
    "        augmented[f0:f0+f, :] = augmented.mean()\n",
    "\n",
    "    for _ in range(n_masks):\n",
    "        t = np.random.randint(0, min(time_mask_param, n_frames))\n",
    "        t0 = np.random.randint(0, max(1, n_frames - t))\n",
    "        augmented[:, t0:t0+t] = augmented.mean()\n",
    "\n",
    "    return augmented\n",
    "\n",
    "\n",
    "def vocal_tract_length_perturbation(samples, sr, alpha=1.0):\n",
    "    \"\"\"Apply VTLP via frequency warping.\"\"\"\n",
    "    D = librosa.stft(samples)\n",
    "    n_fft = (D.shape[0] - 1) * 2\n",
    "    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "    warped_freqs = freqs * alpha\n",
    "\n",
    "    D_warped = np.zeros_like(D)\n",
    "    for i, wf in enumerate(warped_freqs):\n",
    "        if wf < freqs[-1]:\n",
    "            idx = np.searchsorted(freqs, wf)\n",
    "            if idx < len(freqs) - 1:\n",
    "                D_warped[i] = D[idx]\n",
    "\n",
    "    return librosa.istft(D_warped, length=len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d419678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: YAML parsing and speaker mapping\n",
    "\n",
    "def parse_labels_yaml(yaml_path):\n",
    "    if not yaml_path.exists():\n",
    "        return {}\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f) or {}\n",
    "    parsed = {}\n",
    "    for filename, value in data.items():\n",
    "        if isinstance(value, (list, tuple)) and len(value) >= 3:\n",
    "            gender, in_group, speaker_name = value[0], value[1], value[2]\n",
    "            parsed[filename] = {\"gender\": gender, \"in_group\": in_group, \"speaker_name\": speaker_name}\n",
    "        elif isinstance(value, dict):\n",
    "            parsed[filename] = {\n",
    "                \"gender\": value.get(\"gender\", \"Unknown\"),\n",
    "                \"in_group\": value.get(\"in_group\", False),\n",
    "                \"speaker_name\": value.get(\"speaker_name\", yaml_path.parent.name),\n",
    "            }\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def build_speaker_maps(root: Path):\n",
    "    speaker_to_label = {}\n",
    "    label_to_speaker = {}\n",
    "    label_counter = 0\n",
    "    # Collect from yaml\n",
    "    for folder in root.iterdir():\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        meta = parse_labels_yaml(folder / \"labels.yaml\")\n",
    "        for info in meta.values():\n",
    "            spk = info[\"speaker_name\"]\n",
    "            if spk not in speaker_to_label:\n",
    "                speaker_to_label[spk] = label_counter\n",
    "                label_to_speaker[label_counter] = spk\n",
    "                label_counter += 1\n",
    "    # Fallback to folder names\n",
    "    for folder in root.iterdir():\n",
    "        if folder.is_dir() and folder.name not in speaker_to_label:\n",
    "            speaker_to_label[folder.name] = label_counter\n",
    "            label_to_speaker[label_counter] = folder.name\n",
    "            label_counter += 1\n",
    "    return speaker_to_label, label_to_speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e32733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio processing and augmentations\n",
    "\n",
    "def load_audio(path: Path):\n",
    "    \"\"\"Robust audio loader: try soundfile, then librosa (warning-suppressed).\"\"\"\n",
    "    # 1) Try soundfile (fast for WAV/FLAC/OGG)\n",
    "    try:\n",
    "        import soundfile as sf\n",
    "        samples, file_sr = sf.read(str(path), always_2d=False)\n",
    "        if samples.ndim > 1:\n",
    "            samples = samples.mean(axis=1)\n",
    "        samples = samples.astype(np.float32, copy=False)\n",
    "        return samples, int(file_sr)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Fallback to librosa with audioread backend; suppress future warning\n",
    "    import warnings as _warnings\n",
    "    with _warnings.catch_warnings():\n",
    "        _warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"librosa.core.audio\")\n",
    "        samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
    "    samples = samples.astype(np.float32, copy=False)\n",
    "    return samples, int(file_sr)\n",
    "\n",
    "\n",
    "def resample_if_needed(samples, file_sr):\n",
    "    if file_sr == sr:\n",
    "        return samples\n",
    "    return librosa.resample(samples, orig_sr=file_sr, target_sr=sr)\n",
    "\n",
    "\n",
    "def chunk_audio(samples):\n",
    "    chunk_len = int(chunk_duration * sr)\n",
    "    chunks = []\n",
    "    for i in range(0, len(samples), chunk_len):\n",
    "        chunk = samples[i : i + chunk_len]\n",
    "        if len(chunk) < chunk_len:\n",
    "            pad = np.zeros(chunk_len, dtype=chunk.dtype)\n",
    "            pad[: len(chunk)] = chunk\n",
    "            chunk = pad\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def to_logmel(chunk):\n",
    "    mel = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    return librosa.power_to_db(mel, ref=np.max).astype(np.float32)\n",
    "\n",
    "\n",
    "def add_noise(samples):\n",
    "    noise_factor = np.random.uniform(0.002, 0.008)\n",
    "    return samples + np.random.randn(len(samples)) * noise_factor, f\"noise_{noise_factor:.4f}\"\n",
    "\n",
    "\n",
    "def speed_perturb(samples, factor):\n",
    "    return librosa.effects.time_stretch(samples, rate=factor), f\"speed_{factor:.2f}\"\n",
    "\n",
    "\n",
    "def vtlp_stub(samples, alpha):\n",
    "    # Simplified placeholder; keeps timing but tags VTLP for label mapping\n",
    "    return samples, f\"vtlp_{alpha:.2f}\"\n",
    "\n",
    "\n",
    "def spectral_mask(logmel):\n",
    "    lm = logmel.copy()\n",
    "    n_m, n_t = lm.shape\n",
    "    for _ in range(2):\n",
    "        f = np.random.randint(0, min(10, n_m))\n",
    "        f0 = np.random.randint(0, max(1, n_m - f))\n",
    "        lm[f0 : f0 + f, :] = lm.mean()\n",
    "    for _ in range(2):\n",
    "        t = np.random.randint(0, min(20, n_t))\n",
    "        t0 = np.random.randint(0, max(1, n_t - t))\n",
    "        lm[:, t0 : t0 + t] = lm.mean()\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed31385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset traversal and split\n",
    "\n",
    "def process_file(path: Path, speaker_label, speaker_info):\n",
    "    samples, file_sr = load_audio(path)\n",
    "    samples = resample_if_needed(samples, file_sr)\n",
    "    results = []\n",
    "\n",
    "    def logmels_from_samples(arr, tag, is_vtlp=False):\n",
    "        for chunk in chunk_audio(arr):\n",
    "            lm = to_logmel(chunk)\n",
    "            if WITH_SPECTRAL:\n",
    "                lm = spectral_mask(lm)\n",
    "            results.append((lm, tag, is_vtlp))\n",
    "\n",
    "    # original\n",
    "    logmels_from_samples(samples, \"original\", False)\n",
    "\n",
    "    if WITH_NOISE:\n",
    "        noisy, tag = add_noise(samples)\n",
    "        logmels_from_samples(noisy, tag, False)\n",
    "    if WITH_SPEED:\n",
    "        for f in (0.9, 1.1):\n",
    "            try:\n",
    "                sped, tag = speed_perturb(samples, f)\n",
    "                logmels_from_samples(sped, tag, False)\n",
    "            except Exception:\n",
    "                pass\n",
    "    if WITH_VTLP:\n",
    "        for alpha in (0.9, 1.1):\n",
    "            vtlp, tag = vtlp_stub(samples, alpha)\n",
    "            logmels_from_samples(vtlp, tag, True)\n",
    "\n",
    "    labels = []\n",
    "    for _, tag, is_vtlp in results:\n",
    "        if is_vtlp:\n",
    "            labels.append(None)  # to be filled with VTLP mapping later\n",
    "        else:\n",
    "            labels.append(speaker_label)\n",
    "    return results, labels, [speaker_info] * len(results)\n",
    "\n",
    "\n",
    "def collect_data(root: Path):\n",
    "    speaker_to_label, label_to_speaker = build_speaker_maps(root)\n",
    "    specs, labels, aug_tags, is_vtlp_flags, spk_infos, file_paths = [], [], [], [], [], []\n",
    "    vtlp_map = {}\n",
    "    next_vtlp = 10000\n",
    "\n",
    "    for folder in sorted(root.iterdir()):\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        meta = parse_labels_yaml(folder / \"labels.yaml\")\n",
    "        for audio_file in sorted(folder.iterdir()):\n",
    "            if not audio_file.suffix.lower() in SUPPORTED_EXTS:\n",
    "                continue\n",
    "            info = meta.get(audio_file.name, {\"speaker_name\": folder.name, \"gender\": \"Unknown\", \"in_group\": True})\n",
    "            spk = info[\"speaker_name\"]\n",
    "            speaker_label = speaker_to_label[spk]\n",
    "            res, lbls, infos = process_file(audio_file, speaker_label, info)\n",
    "            for (lm, tag, is_vtlp), lbl, inf in zip(res, lbls, infos):\n",
    "                if is_vtlp:\n",
    "                    key = (speaker_label, tag)\n",
    "                    if key not in vtlp_map:\n",
    "                        vtlp_map[key] = next_vtlp\n",
    "                        next_vtlp += 1\n",
    "                    lbl = vtlp_map[key]\n",
    "                specs.append(lm)\n",
    "                labels.append(lbl)\n",
    "                aug_tags.append(tag)\n",
    "                is_vtlp_flags.append(is_vtlp)\n",
    "                spk_infos.append(inf)\n",
    "                file_paths.append(str(audio_file))\n",
    "    return specs, labels, aug_tags, is_vtlp_flags, spk_infos, file_paths, speaker_to_label, label_to_speaker, vtlp_map\n",
    "\n",
    "\n",
    "def split_80_10_10(file_paths, specs, labels, aug_tags, is_vtlp_flags, spk_infos):\n",
    "    file_to_idx = defaultdict(list)\n",
    "    for i, fp in enumerate(file_paths):\n",
    "        file_to_idx[fp].append(i)\n",
    "    files = list(file_to_idx.keys())\n",
    "    random.shuffle(files)\n",
    "    n = len(files)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_test = int(0.1 * n)\n",
    "    train_files = set(files[:n_train])\n",
    "    test_files = set(files[n_train : n_train + n_test])\n",
    "    val_files = set(files[n_train + n_test :])\n",
    "\n",
    "    def gather(selected):\n",
    "        idxs = [i for f in selected for i in file_to_idx[f]]\n",
    "        return {\n",
    "            \"specs\": [specs[i] for i in idxs],\n",
    "            \"labels\": [labels[i] for i in idxs],\n",
    "            \"aug_tags\": [aug_tags[i] for i in idxs],\n",
    "            \"is_vtlp\": [is_vtlp_flags[i] for i in idxs],\n",
    "            \"file_paths\": [file_paths[i] for i in idxs],\n",
    "            \"speaker_info\": [spk_infos[i] for i in idxs],\n",
    "        }\n",
    "\n",
    "    splits = {\n",
    "        \"train\": gather(train_files),\n",
    "        \"val\": gather(val_files),\n",
    "        \"test\": gather(test_files),\n",
    "    }\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18189c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 writing\n",
    "\n",
    "def save_h5(splits, speaker_to_label, label_to_speaker, vtlp_map, out_path: Path):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(out_path, \"w\") as f:\n",
    "        for split_name, data in splits.items():\n",
    "            if len(data[\"specs\"]) == 0:\n",
    "                continue\n",
    "            n_items = len(data[\"specs\"])\n",
    "            n_mels_local = data[\"specs\"][0].shape[0]\n",
    "            max_T = max(s.shape[1] for s in data[\"specs\"])\n",
    "            arr = np.full((n_items, n_mels_local, max_T), fill_value=-80.0, dtype=np.float32)\n",
    "            lengths = np.zeros(n_items, dtype=np.int64)\n",
    "            for i, s in enumerate(data[\"specs\"]):\n",
    "                T = s.shape[1]\n",
    "                arr[i, :, :T] = s\n",
    "                lengths[i] = T\n",
    "            grp = f.create_group(split_name)\n",
    "            grp.create_dataset(\"logmel\", data=arr, compression=\"gzip\")\n",
    "            grp.create_dataset(\"label\", data=np.array(data[\"labels\"], dtype=np.int64), compression=\"gzip\")\n",
    "            grp.create_dataset(\"length\", data=lengths, compression=\"gzip\")\n",
    "            dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "            grp.create_dataset(\"augmentation\", data=np.array(data[\"aug_tags\"], dtype=dt), compression=\"gzip\")\n",
    "            grp.create_dataset(\"file_path\", data=np.array(data[\"file_paths\"], dtype=dt), compression=\"gzip\")\n",
    "        meta = f.create_group(\"meta\")\n",
    "        meta.attrs.update({\n",
    "            \"sample_rate\": sr,\n",
    "            \"feature_type\": \"log-mel spectrogram\",\n",
    "            \"total_speakers\": len(speaker_to_label),\n",
    "        })\n",
    "        file_desc = {\n",
    "            \"dataset_name\": out_path.name,\n",
    "            \"preprocessing_config\": {\n",
    "                \"sr\": sr,\n",
    "                \"n_mels\": n_mels,\n",
    "                \"n_fft\": n_fft,\n",
    "                \"hop_length\": hop_length,\n",
    "                \"chunk_duration\": chunk_duration,\n",
    "                \"with_noise\": WITH_NOISE,\n",
    "                \"with_speed\": WITH_SPEED,\n",
    "                \"with_vtlp\": WITH_VTLP,\n",
    "                \"with_spectral\": WITH_SPECTRAL,\n",
    "            },\n",
    "            \"split_strategy\": \"80-10-10 by file\",\n",
    "        }\n",
    "        meta.create_dataset(\"file_description.yaml\", data=np.bytes_(yaml.safe_dump(file_desc)))\n",
    "        speaker_mapping = {k: int(v) for k, v in speaker_to_label.items()}\n",
    "        meta.create_dataset(\"speaker_mapping.yaml\", data=np.bytes_(yaml.safe_dump({\"speakers\": speaker_mapping})))\n",
    "        meta.create_dataset(\"split_statistics.json\", data=np.bytes_(json.dumps({}, indent=2).encode(\"utf-8\")))\n",
    "    print(f\"Saved HDF5 â†’ {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c423fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n",
      "C:\\Users\\pczec\\AppData\\Local\\Temp\\ipykernel_32212\\415391012.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, file_sr = librosa.load(str(path), sr=None, mono=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 37061 | Base speakers: 5 | VTLP variants: 0\n",
      "Building splits (80/10/10 by file)...\n",
      "Saving HDF5...\n",
      "Saved HDF5 â†’ c:\\Users\\pczec\\Desktop\\Studia\\SEM5\\IML\\IML-PW\\outputs\\logmels_aug_26-01-25_10-04-39.h5\n",
      "Done in 507.2s\n",
      "Saved to: c:\\Users\\pczec\\Desktop\\Studia\\SEM5\\IML\\IML-PW\\outputs\\logmels_aug_26-01-25_10-04-39.h5\n"
     ]
    }
   ],
   "source": [
    "# Run: build and save HDF5\n",
    "\n",
    "start = time.time()\n",
    "print(\"Collecting data...\")\n",
    "(specs, labels, aug_tags, is_vtlp_flags, spk_infos, file_paths,\n",
    " speaker_to_label, label_to_speaker, vtlp_map) = collect_data(data_root)\n",
    "print(f\"Total chunks: {len(specs)} | Base speakers: {len(speaker_to_label)} | VTLP variants: {len(vtlp_map)}\")\n",
    "\n",
    "print(\"Building splits (80/10/10 by file)...\")\n",
    "splits = split_80_10_10(file_paths, specs, labels, aug_tags, is_vtlp_flags, spk_infos)\n",
    "\n",
    "# Include date and time to avoid collisions\n",
    "out_name = f\"logmels_{'aug' if any([WITH_NOISE, WITH_SPEED, WITH_VTLP, WITH_SPECTRAL]) else 'noaug'}_{time.strftime('%y-%m-%d_%H-%M-%S')}.h5\"\n",
    "out_path = output_dir / out_name\n",
    "\n",
    "print(\"Saving HDF5...\")\n",
    "save_h5(splits, speaker_to_label, label_to_speaker, vtlp_map, out_path)\n",
    "print(f\"Done in {time.time() - start:.1f}s\")\n",
    "print(f\"Saved to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

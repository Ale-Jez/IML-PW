{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4873c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Running on: cuda\n",
      "‚è≥ Loading Model (58 Classes)...\n",
      "‚úÖ Model loaded successfully!\n",
      "üìÇ Found 31 WAV files in 'Recordings_1/Aleksander'\n",
      "üéØ Target Class: 1 (Member)\n",
      "\n",
      "FILENAME                                 | PREDICTION      | CONFIDENCE | ID | STATUS\n",
      "-----------------------------------------------------------------------------------------------\n",
      "adi.wav                                  | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "Alexander-aleksander.wav                 | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "churchill-1.wav                          | ‚ùå OUTSIDER      | 99.5%      | 8  | MATCH\n",
      "fdr.wav                                  | ‚ùå OUTSIDER      | 99.4%      | 11 | MATCH\n",
      "Gallic-Wars-Aleksander.wav               | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "gatsby-ania.wav                          | ‚ùå OUTSIDER      | 100.0%      | 3  | MATCH\n",
      "grian-1.wav                              | ‚ùå OUTSIDER      | 98.8%      | 13 | MATCH\n",
      "grian-2.wav                              | ‚ùå OUTSIDER      | 100.0%      | 13 | MATCH\n",
      "grian-3.wav                              | ‚ùå OUTSIDER      | 98.2%      | 13 | MATCH\n",
      "holmes-Lena.wav                          | ‚ùå OUTSIDER      | 100.0%      | 24 | MATCH\n",
      "invocation-Pan-Tadeusz.wav               | ‚ùå OUTSIDER      | 100.0%      | 42 | MATCH\n",
      "jfk-1.wav                                | ‚ùå OUTSIDER      | 100.0%      | 16 | MATCH\n",
      "jfk-2-1.wav                              | ‚ùå OUTSIDER      | 100.0%      | 16 | MATCH\n",
      "jfk-3.wav                                | ‚ùå OUTSIDER      | 100.0%      | 16 | MATCH\n",
      "kryptyda.wav                             | ‚ùå OUTSIDER      | 100.0%      | 22 | MATCH\n",
      "Napoleon-aleksander.wav                  | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "oppenheimer.wav                          | ‚ùå OUTSIDER      | 100.0%      | 35 | MATCH\n",
      "oversimplified-1.wav                     | ‚ùå OUTSIDER      | 99.9%      | 36 | MATCH\n",
      "oversimplified-2.wav                     | ‚ùå OUTSIDER      | 99.0%      | 36 | MATCH\n",
      "pati-glacier.wav                         | ‚ùå OUTSIDER      | 100.0%      | 37 | MATCH\n",
      "prince-Aleksander.wav                    | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "queen-1.wav                              | ‚ùå OUTSIDER      | 100.0%      | 52 | MATCH\n",
      "queen-2.wav                              | ‚ùå OUTSIDER      | 99.7%      | 52 | MATCH\n",
      "queen-3.wav                              | ‚ùå OUTSIDER      | 100.0%      | 52 | MATCH\n",
      "queen-4.wav                              | ‚ùå OUTSIDER      | 100.0%      | 52 | MATCH\n",
      "reagan-1.wav                             | ‚ùå OUTSIDER      | 100.0%      | 41 | MATCH\n",
      "reagan-2.wav                             | ‚ùå OUTSIDER      | 100.0%      | 41 | MATCH\n",
      "sartre-ania.wav                          | ‚ùå OUTSIDER      | 100.0%      | 3  | MATCH\n",
      "thatcher.wav                             | ‚ùå OUTSIDER      | 100.0%      | 43 | MATCH\n",
      "tiffany-Ania.wav                         | ‚ùå OUTSIDER      | 100.0%      | 3  | MATCH\n",
      "trump.wav                                | ‚ùå OUTSIDER      | 99.9%      | 56 | MATCH\n",
      "\n",
      "========================================\n",
      "üìä ACCURACY REPORT\n",
      "========================================\n",
      "üë§ Members (Aleksander): 4/4 (100.0%)\n",
      "üö´ Outsiders (Imposters): 27/27 (100.0%)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. IMPORTS\n",
    "# ==========================================\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è Running on: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# Path to the 58-class checkpoint (The one that works!)\n",
    "CHECKPOINT_PATH = \"checkpoints/train43/best_model.pt\"\n",
    "\n",
    "# Folder with recordings to test (Aleksander)\n",
    "TEST_AUDIO_FOLDER = r\"Recordings_1/Aleksander\"\n",
    "\n",
    "# üéØ GROUND TRUTH\n",
    "# We expect Aleksander to be identified as Class 1.\n",
    "# Anyone else in this folder is an imposter.\n",
    "EXPECTED_ID = 1 \n",
    "\n",
    "# Model Params (Must match training)\n",
    "N_MELS = 64\n",
    "EMBED_DIM = 256\n",
    "NUM_SPEAKERS = 58 \n",
    "\n",
    "# Logic: Convert specific IDs to \"Member\"\n",
    "# Based on your logs: Aleksander(1), Mantas(27), Michal(29), Piotr(38), Rafal(40)\n",
    "IN_GROUP_IDS = [1, 27, 29, 38, 40]\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.60 \n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        hidden = max(channels // reduction, 4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, hidden, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        B, C, T, F = x.shape\n",
    "        s = x.mean(dim=(2, 3))\n",
    "        w = self.fc(s).view(B, C, 1, 1)\n",
    "        return x * w\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, no_mels, embed_dim, rnn_hidden, rnn_layers, bidir):\n",
    "        super().__init__()\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            SEBlock(32, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            SEBlock(64, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            SEBlock(128, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "        self.rnn_hidden = rnn_hidden\n",
    "        self.rnn = nn.GRU(input_size=128 * (no_mels // 8), hidden_size=self.rnn_hidden,\n",
    "                          num_layers=rnn_layers, bidirectional=bidir, batch_first=True, dropout=0.2)\n",
    "        out_dim = (2 if bidir else 1) * rnn_hidden\n",
    "        self.rnn_ln = nn.LayerNorm(out_dim)\n",
    "        self.att = nn.Sequential(nn.Linear(out_dim, 128), nn.Tanh(), nn.Linear(128, 1))\n",
    "        self.proj = nn.Sequential(nn.Linear(out_dim*2, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.cnn_block(x)\n",
    "        \n",
    "        # FIX: Rename frequency var to 'Freq' to avoid shadowing torch.nn.functional (F)\n",
    "        B, C, T, Freq = h.shape  \n",
    "        h = h.permute(0, 2, 1, 3).contiguous().view(B, T, C * Freq)\n",
    "        \n",
    "        rnn_out, _ = self.rnn(h)\n",
    "        rnn_out = self.rnn_ln(rnn_out)\n",
    "        a = self.att(rnn_out).squeeze(-1)\n",
    "        w = torch.softmax(a, dim=1).unsqueeze(-1)\n",
    "        mean = torch.sum(w * rnn_out, dim=1)\n",
    "        var = torch.sum(w * (rnn_out - mean.unsqueeze(1))**2, dim=1)\n",
    "        std = torch.sqrt(var + 1e-5)\n",
    "        stats = torch.cat([mean, std], 1)\n",
    "        z = self.proj(stats)\n",
    "        \n",
    "        # Now 'F' correctly refers to torch.nn.functional\n",
    "        return F.normalize(z, p=2, dim=1)\n",
    "\n",
    "class AAMSoftmax(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.20):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    def forward(self, emb):\n",
    "        W = F.normalize(self.weight, dim=1)\n",
    "        return emb @ W.T * self.s\n",
    "\n",
    "class SpeakerClassifier(nn.Module):\n",
    "    def __init__(self, backbone, num_speakers):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.aamsm = AAMSoftmax(256, num_speakers)\n",
    "    def forward(self, x):\n",
    "        emb = self.backbone(x)\n",
    "        return self.aamsm(emb)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPROCESSING (MATCHING TRAINING)\n",
    "# ==========================================\n",
    "\n",
    "def preprocess_file(file_path):\n",
    "    try:\n",
    "        # 1. Load Audio\n",
    "        y, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        \n",
    "        # 2. Trim Silence (Optional but good)\n",
    "        y, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        if len(y) < 1000: return None\n",
    "\n",
    "        # 3. Volume Normalization (Peak Norm) - Matches AudioPreprocessor.normalize_volume\n",
    "        y = y / (np.max(np.abs(y)) + 1e-9)\n",
    "\n",
    "        # 4. Chunking (3.0s chunks)\n",
    "        chunk_len = int(3.0 * 16000)\n",
    "        stride = int(2.0 * 16000)\n",
    "        chunks = []\n",
    "        \n",
    "        if len(y) < chunk_len:\n",
    "            y = np.pad(y, (0, chunk_len - len(y)))\n",
    "            chunks.append(y)\n",
    "        else:\n",
    "            for i in range(0, len(y) - chunk_len + 1, stride):\n",
    "                chunks.append(y[i : i + chunk_len])\n",
    "        \n",
    "        mels = []\n",
    "        for c in chunks:\n",
    "            # 5. Compute Mel Spectrogram (Exact Parameters from prepare_h5.ipynb)\n",
    "            mel = librosa.feature.melspectrogram(\n",
    "                y=c, \n",
    "                sr=16000, \n",
    "                n_fft=2048,       # Training used 2048\n",
    "                hop_length=512,   # Training used 512\n",
    "                n_mels=N_MELS\n",
    "            )\n",
    "            \n",
    "            # 6. Log-Mel Scaling (Match Training: ref=np.max)\n",
    "            log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            \n",
    "            # Transpose to [Time, Freq]\n",
    "            mels.append(log_mel.T)\n",
    "            \n",
    "        return torch.tensor(np.array(mels), dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "print(f\"‚è≥ Loading Model ({NUM_SPEAKERS} Classes)...\")\n",
    "backbone = Backbone(no_mels=N_MELS, embed_dim=EMBED_DIM, rnn_hidden=256, rnn_layers=2, bidir=True)\n",
    "model = SpeakerClassifier(backbone, num_speakers=NUM_SPEAKERS)\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False) \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
    "\n",
    "# Search ONLY for WAV files (since we converted them)\n",
    "audio_files = glob.glob(os.path.join(TEST_AUDIO_FOLDER, \"*.wav\"))\n",
    "\n",
    "print(f\"üìÇ Found {len(audio_files)} WAV files in '{TEST_AUDIO_FOLDER}'\")\n",
    "print(f\"üéØ Target Class: {EXPECTED_ID} (Member)\\n\")\n",
    "\n",
    "print(f\"{'FILENAME':<40} | {'PREDICTION':<15} | {'CONFIDENCE'} | {'ID'} | {'STATUS'}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "results = []\n",
    "correct_members = 0\n",
    "correct_outsiders = 0\n",
    "total_members = 0\n",
    "total_outsiders = 0\n",
    "\n",
    "# Updated list of files that are ACTUALLY Aleksander\n",
    "# (Based on your CSV analysis)\n",
    "TRUE_MEMBER_FILES = [\n",
    "    \"Alexander-aleksander.wav\",\n",
    "    \"Gallic-Wars-Aleksander.wav\",\n",
    "    \"Napoleon-aleksander.wav\",\n",
    "    \"prince-Aleksander.wav\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file_path in audio_files:\n",
    "        batch = preprocess_file(file_path)\n",
    "        if batch is None: continue\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        chunk_conf, chunk_ids = torch.max(probs, dim=1)\n",
    "        votes = chunk_ids.cpu().tolist()\n",
    "        pred_id = max(set(votes), key=votes.count)\n",
    "        avg_conf = chunk_conf.mean().item()\n",
    "        \n",
    "        # --- BINARY LOGIC ---\n",
    "        if pred_id in IN_GROUP_IDS:\n",
    "            if avg_conf >= CONFIDENCE_THRESHOLD:\n",
    "                label = \"‚úÖ MEMBER\"\n",
    "                pred_class = 1 # Access Granted\n",
    "            else:\n",
    "                label = \"‚ùì LOW CONF (1)\"\n",
    "                pred_class = 0 # Reject if unsure\n",
    "        else:\n",
    "            label = \"‚ùå OUTSIDER\"\n",
    "            pred_class = 0 # Access Denied\n",
    "            \n",
    "        fname = os.path.basename(file_path)\n",
    "        \n",
    "        # --- GROUND TRUTH CHECK ---\n",
    "        is_actually_member = fname in TRUE_MEMBER_FILES\n",
    "        \n",
    "        if is_actually_member:\n",
    "            total_members += 1\n",
    "            if pred_class == 1: \n",
    "                correct_members += 1\n",
    "                status = \"MATCH\"\n",
    "            else:\n",
    "                status = \"MISS\" # Should have been member\n",
    "        else:\n",
    "            total_outsiders += 1\n",
    "            if pred_class == 0: \n",
    "                correct_outsiders += 1\n",
    "                status = \"MATCH\"\n",
    "            else:\n",
    "                status = \"FALSE ACCEPT\" # Dangerous!\n",
    "        \n",
    "        print(f\"{fname[:38]:<40} | {label:<15} | {avg_conf:.1%}      | {pred_id:<2} | {status}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"file\": fname,\n",
    "            \"prediction\": label,\n",
    "            \"raw_id\": pred_id,\n",
    "            \"confidence\": avg_conf\n",
    "        })\n",
    "\n",
    "# Final Report\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üìä ACCURACY REPORT\")\n",
    "print(\"=\"*40)\n",
    "if total_members > 0:\n",
    "    print(f\"üë§ Members (Aleksander): {correct_members}/{total_members} ({(correct_members/total_members)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"üë§ Members (Aleksander): 0/0 (No files found)\")\n",
    "\n",
    "if total_outsiders > 0:\n",
    "    print(f\"üö´ Outsiders (Imposters): {correct_outsiders}/{total_outsiders} ({(correct_outsiders/total_outsiders)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"üö´ Outsiders (Imposters): 0/0 (No files found)\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189d4b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Running on: cuda\n",
      "‚è≥ Loading Binary Model (2 Classes)...\n",
      "‚úÖ Model loaded successfully!\n",
      "üìÇ Found 31 WAV files in 'Recordings_1/Aleksander'\n",
      "üéØ Target: Class 1 (Member)\n",
      "\n",
      "FILENAME                                 | PREDICTION      | CONFIDENCE | ID | STATUS\n",
      "-----------------------------------------------------------------------------------------------\n",
      "adi.wav                                  | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "Alexander-aleksander.wav                 | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "churchill-1.wav                          | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "fdr.wav                                  | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "Gallic-Wars-Aleksander.wav               | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "gatsby-ania.wav                          | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "grian-1.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "grian-2.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "grian-3.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "holmes-Lena.wav                          | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "invocation-Pan-Tadeusz.wav               | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "jfk-1.wav                                | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "jfk-2-1.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "jfk-3.wav                                | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "kryptyda.wav                             | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "Napoleon-aleksander.wav                  | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "oppenheimer.wav                          | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "oversimplified-1.wav                     | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "oversimplified-2.wav                     | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "pati-glacier.wav                         | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "prince-Aleksander.wav                    | ‚úÖ MEMBER        | 100.0%      | 1  | MATCH\n",
      "queen-1.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "queen-2.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "queen-3.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "queen-4.wav                              | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "reagan-1.wav                             | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "reagan-2.wav                             | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "sartre-ania.wav                          | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "thatcher.wav                             | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "tiffany-Ania.wav                         | ‚ùå OUTSIDER      | 100.0%      | 0  | MATCH\n",
      "trump.wav                                | ‚ùå OUTSIDER      | 99.9%      | 0  | MATCH\n",
      "\n",
      "========================================\n",
      "üìä BINARY MODEL ACCURACY REPORT\n",
      "========================================\n",
      "üë§ Members (Aleksander): 4/4 (100.0%)\n",
      "üö´ Outsiders (Imposters): 27/27 (100.0%)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. IMPORTS\n",
    "# ==========================================\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è Running on: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# Path to the BINARY checkpoint\n",
    "CHECKPOINT_PATH = \"checkpoints/train31/best_model.pt\"\n",
    "\n",
    "# Folder with recordings (Aleksander)\n",
    "TEST_AUDIO_FOLDER = r\"Recordings_1/Aleksander\"\n",
    "\n",
    "# üéØ Target Class: 1 (Member)\n",
    "# We want to see if Aleksander gets predicted as 1.\n",
    "EXPECTED_CLASS = 1 \n",
    "\n",
    "# Model Params (Binary = 2 Speakers)\n",
    "NUM_SPEAKERS = 2 \n",
    "N_MELS = 64\n",
    "EMBED_DIM = 256\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.50\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        hidden = max(channels // reduction, 4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, hidden, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        B, C, T, F = x.shape\n",
    "        s = x.mean(dim=(2, 3))\n",
    "        w = self.fc(s).view(B, C, 1, 1)\n",
    "        return x * w\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, no_mels, embed_dim, rnn_hidden, rnn_layers, bidir):\n",
    "        super().__init__()\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            SEBlock(32, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            SEBlock(64, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            SEBlock(128, reduction=8), nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "        self.rnn_hidden = rnn_hidden\n",
    "        self.rnn = nn.GRU(input_size=128 * (no_mels // 8), hidden_size=self.rnn_hidden,\n",
    "                          num_layers=rnn_layers, bidirectional=bidir, batch_first=True, dropout=0.2)\n",
    "        out_dim = (2 if bidir else 1) * rnn_hidden\n",
    "        self.rnn_ln = nn.LayerNorm(out_dim)\n",
    "        self.att = nn.Sequential(nn.Linear(out_dim, 128), nn.Tanh(), nn.Linear(128, 1))\n",
    "        self.proj = nn.Sequential(nn.Linear(out_dim*2, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.cnn_block(x)\n",
    "        \n",
    "        # CORRECT RESHAPE LOGIC\n",
    "        B, C, T, Freq = h.shape  \n",
    "        h = h.permute(0, 2, 1, 3).contiguous().view(B, T, C * Freq)\n",
    "        \n",
    "        rnn_out, _ = self.rnn(h)\n",
    "        rnn_out = self.rnn_ln(rnn_out)\n",
    "        a = self.att(rnn_out).squeeze(-1)\n",
    "        w = torch.softmax(a, dim=1).unsqueeze(-1)\n",
    "        mean = torch.sum(w * rnn_out, dim=1)\n",
    "        var = torch.sum(w * (rnn_out - mean.unsqueeze(1))**2, dim=1)\n",
    "        std = torch.sqrt(var + 1e-5)\n",
    "        stats = torch.cat([mean, std], 1)\n",
    "        z = self.proj(stats)\n",
    "        return F.normalize(z, p=2, dim=1)\n",
    "\n",
    "class AAMSoftmax(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.20):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    def forward(self, emb):\n",
    "        W = F.normalize(self.weight, dim=1)\n",
    "        return emb @ W.T * self.s\n",
    "\n",
    "class SpeakerClassifier(nn.Module):\n",
    "    def __init__(self, backbone, num_speakers):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.aamsm = AAMSoftmax(256, num_speakers)\n",
    "    def forward(self, x):\n",
    "        emb = self.backbone(x)\n",
    "        return self.aamsm(emb)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREPROCESSING (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def preprocess_file(file_path):\n",
    "    try:\n",
    "        # 1. Load Audio\n",
    "        y, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "        y, _ = librosa.effects.trim(y, top_db=20)\n",
    "        \n",
    "        if len(y) < 1000: return None\n",
    "\n",
    "        # 2. Volume Normalization (Peak Norm) - Matches Training!\n",
    "        y = y / (np.max(np.abs(y)) + 1e-9)\n",
    "\n",
    "        # 3. Chunking (3.0s chunks)\n",
    "        chunk_len = int(3.0 * 16000)\n",
    "        stride = int(2.0 * 16000)\n",
    "        chunks = []\n",
    "        \n",
    "        if len(y) < chunk_len:\n",
    "            y = np.pad(y, (0, chunk_len - len(y)))\n",
    "            chunks.append(y)\n",
    "        else:\n",
    "            for i in range(0, len(y) - chunk_len + 1, stride):\n",
    "                chunks.append(y[i : i + chunk_len])\n",
    "        \n",
    "        mels = []\n",
    "        for c in chunks:\n",
    "            # 4. Mel Spectrogram (Exact Parameters from prepare_h5.ipynb)\n",
    "            mel = librosa.feature.melspectrogram(\n",
    "                y=c, \n",
    "                sr=16000, \n",
    "                n_fft=2048,       # Fixed\n",
    "                hop_length=512,   # Fixed\n",
    "                n_mels=N_MELS\n",
    "            )\n",
    "            \n",
    "            # 5. Log-Mel Scaling (Match Training: ref=np.max)\n",
    "            log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            \n",
    "            mels.append(log_mel.T)\n",
    "            \n",
    "        return torch.tensor(np.array(mels), dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "print(f\"‚è≥ Loading Binary Model ({NUM_SPEAKERS} Classes)...\")\n",
    "backbone = Backbone(no_mels=N_MELS, embed_dim=EMBED_DIM, rnn_hidden=256, rnn_layers=2, bidir=True)\n",
    "model = SpeakerClassifier(backbone, num_speakers=NUM_SPEAKERS)\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    # strict=False allows loading despite minor key differences\n",
    "    model.load_state_dict(state_dict, strict=False) \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
    "\n",
    "# Search ONLY for WAV files\n",
    "audio_files = glob.glob(os.path.join(TEST_AUDIO_FOLDER, \"*.wav\"))\n",
    "\n",
    "print(f\"üìÇ Found {len(audio_files)} WAV files in '{TEST_AUDIO_FOLDER}'\")\n",
    "print(f\"üéØ Target: Class {EXPECTED_CLASS} (Member)\\n\")\n",
    "\n",
    "print(f\"{'FILENAME':<40} | {'PREDICTION':<15} | {'CONFIDENCE'} | {'ID'} | {'STATUS'}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "results = []\n",
    "correct_members = 0\n",
    "correct_outsiders = 0\n",
    "total_members = 0\n",
    "total_outsiders = 0\n",
    "\n",
    "# True Member Files (Aleksander)\n",
    "TRUE_MEMBER_FILES = [\n",
    "    \"Alexander-aleksander.wav\",\n",
    "    \"Gallic-Wars-Aleksander.wav\",\n",
    "    \"Napoleon-aleksander.wav\",\n",
    "    \"prince-Aleksander.wav\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file_path in audio_files:\n",
    "        batch = preprocess_file(file_path)\n",
    "        if batch is None: continue\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        chunk_conf, chunk_ids = torch.max(probs, dim=1)\n",
    "        votes = chunk_ids.cpu().tolist()\n",
    "        \n",
    "        # Binary Prediction: 0 or 1\n",
    "        pred_id = max(set(votes), key=votes.count)\n",
    "        avg_conf = chunk_conf.mean().item()\n",
    "        \n",
    "        # --- DECISION LOGIC ---\n",
    "        if pred_id == 1:\n",
    "            if avg_conf >= CONFIDENCE_THRESHOLD:\n",
    "                label = \"‚úÖ MEMBER\"\n",
    "            else:\n",
    "                label = \"‚ùì LOW CONF (1)\"\n",
    "        else:\n",
    "            label = \"‚ùå OUTSIDER\"\n",
    "            \n",
    "        fname = os.path.basename(file_path)\n",
    "        \n",
    "        # --- GROUND TRUTH CHECK ---\n",
    "        is_actually_member = fname in TRUE_MEMBER_FILES\n",
    "        \n",
    "        if is_actually_member:\n",
    "            total_members += 1\n",
    "            if pred_id == 1: \n",
    "                correct_members += 1\n",
    "                status = \"MATCH\"\n",
    "            else:\n",
    "                status = \"MISS\"\n",
    "        else:\n",
    "            total_outsiders += 1\n",
    "            if pred_id == 0: \n",
    "                correct_outsiders += 1\n",
    "                status = \"MATCH\"\n",
    "            else:\n",
    "                status = \"FALSE ACCEPT\" \n",
    "        \n",
    "        print(f\"{fname[:38]:<40} | {label:<15} | {avg_conf:.1%}      | {pred_id:<2} | {status}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"file\": fname,\n",
    "            \"prediction\": label,\n",
    "            \"raw_id\": pred_id,\n",
    "            \"confidence\": avg_conf\n",
    "        })\n",
    "\n",
    "# Final Report\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üìä BINARY MODEL ACCURACY REPORT\")\n",
    "print(\"=\"*40)\n",
    "if total_members > 0:\n",
    "    print(f\"üë§ Members (Aleksander): {correct_members}/{total_members} ({(correct_members/total_members)*100:.1f}%)\")\n",
    "if total_outsiders > 0:\n",
    "    print(f\"üö´ Outsiders (Imposters): {correct_outsiders}/{total_outsiders} ({(correct_outsiders/total_outsiders)*100:.1f}%)\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

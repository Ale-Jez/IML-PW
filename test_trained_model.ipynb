{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71d743d",
   "metadata": {},
   "source": [
    "# ğŸ§ª Model Testing & Evaluation Notebook\n",
    "\n",
    "This notebook is dedicated to **testing and evaluating a pre-trained speaker verification model**.\n",
    "\n",
    "## ğŸ“‹ Overview\n",
    "\n",
    "This notebook is separated from training to allow:\n",
    "1. **Fast iteration** on evaluation without re-running training\n",
    "2. **Testing different thresholds** for access control\n",
    "3. **Evaluating on new test sets** without loading training code\n",
    "4. **Generating reports** for model performance\n",
    "\n",
    "## ğŸ”„ Workflow\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TRAINING NOTEBOOK                             â”‚\n",
    "â”‚  voice_recognition_rnn_cnn.ipynb                                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚  â”‚ Dataset  â”‚ â†’ â”‚ Training â”‚ â†’ â”‚ Save Checkpoint  â”‚            â”‚\n",
    "â”‚  â”‚ (.h5)    â”‚   â”‚ Loop     â”‚   â”‚ (best_model.pt)  â”‚            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 THIS NOTEBOOK (Testing)                          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Load Checkpoint  â”‚ â†’ â”‚ Load Test Data   â”‚ â†’ â”‚ Evaluate   â”‚  â”‚\n",
    "â”‚  â”‚ (best_model.pt)  â”‚   â”‚ (test split)     â”‚   â”‚ & Report   â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ğŸ“ Required Files\n",
    "\n",
    "- **Checkpoint**: `checkpoints/trainXX/best_model.pt` (trained model weights)\n",
    "- **Dataset**: `outputs/logmels_*.h5` (HDF5 file with test split)\n",
    "- **Model Definitions**: Model classes are re-defined here (or can be imported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c537d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“‚ AVAILABLE DATASETS\n",
      "======================================================================\n",
      "   1. outputs\\logmels_binary_aug_26-01-27_20-44-16.h5 (1537.0 MB, 2026-01-27 20:45)\n",
      "   2. outputs\\logmels_binary_aug_26-01-27_20-27-44.h5 (1512.5 MB, 2026-01-27 20:28)\n",
      "   3. outputs\\logmels_spkid_aug_26-01-27_16-06-04.h5 (1537.1 MB, 2026-01-27 16:08)\n",
      "   4. outputs\\logmels_spkid_aug_26-01-27_14-26-54.h5 (1274.5 MB, 2026-01-27 14:29)\n",
      "   5. outputs\\logmels_binary_aug_26-01-27_11-49-30.h5 (1274.5 MB, 2026-01-27 11:51)\n",
      "   6. outputs\\logmels_binary_aug_26-01-27_01-12-27.h5 (1274.5 MB, 2026-01-27 01:13)\n",
      "   7. outputs\\logmels_binary_aug_26-01-26_15-26-21.h5 (712.1 MB, 2026-01-26 15:27)\n",
      "\n",
      "======================================================================\n",
      "ğŸ“ AVAILABLE CHECKPOINTS\n",
      "======================================================================\n",
      "   1. checkpoints\\train44 [âœ“] (2026-01-27 15:02)\n",
      "   2. checkpoints\\train43 [âœ“] (2026-01-27 14:33)\n",
      "   3. checkpoints\\train42 [âœ“] (2026-01-27 13:42)\n",
      "   4. checkpoints\\train41 [âœ“] (2026-01-27 12:30)\n",
      "   5. checkpoints\\train40 [âœ“] (2026-01-27 12:10)\n",
      "   6. checkpoints\\train39 [âœ“] (2026-01-27 01:51)\n",
      "   7. checkpoints\\train38 [âœ“] (2026-01-27 01:43)\n",
      "   8. checkpoints\\train37 [âœ“] (2026-01-27 01:24)\n",
      "   9. checkpoints\\train36 [âœ“] (2026-01-27 00:58)\n",
      "   10. checkpoints\\train35 [âœ—] (2026-01-27 00:45)\n",
      "\n",
      "âœ… Selected Dataset: outputs/logmels_binary_aug_26-01-27_11-49-30.h5\n",
      "âœ… Selected Checkpoint: checkpoints/train42/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: IMPORTS AND ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "# Core libraries for model testing and evaluation\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import h5py\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, f1_score, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ============================================================================\n",
    "# SELECT DATASET AND CHECKPOINT\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“‚ AVAILABLE DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "available_datasets = sorted(glob.glob(\"outputs/logmels_*.h5\"), key=os.path.getmtime, reverse=True)\n",
    "for i, ds in enumerate(available_datasets[:10]):\n",
    "    size_mb = os.path.getsize(ds) / (1024*1024)\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(ds)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print(f\"   {i+1}. {ds} ({size_mb:.1f} MB, {mtime})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ AVAILABLE CHECKPOINTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "checkpoint_dirs = sorted(glob.glob(\"checkpoints/train*\"), key=os.path.getmtime, reverse=True)\n",
    "for i, cp in enumerate(checkpoint_dirs[:10]):\n",
    "    best_path = os.path.join(cp, \"best_model.pt\")\n",
    "    exists = \"âœ“\" if os.path.exists(best_path) else \"âœ—\"\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(cp)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "    print(f\"   {i+1}. {cp} [{exists}] ({mtime})\")\n",
    "\n",
    "# ============================================================================\n",
    "# âš ï¸ CONFIGURE THESE PATHS\n",
    "# ============================================================================\n",
    "# Select which dataset and checkpoint to use:\n",
    "#dataset_path = available_datasets[0] if available_datasets else \"outputs/logmels_aug.h5\"\n",
    "#checkpoint_path = os.path.join(checkpoint_dirs[0], \"best_model.pt\") if checkpoint_dirs else \"checkpoints/train1/best_model.pt\"\n",
    "\n",
    "dataset_path = \"outputs/logmels_binary_aug_26-01-27_11-49-30.h5\"\n",
    "checkpoint_path = \"checkpoints/train42/best_model.pt\"\n",
    "\n",
    "print(f\"\\nâœ… Selected Dataset: {dataset_path}\")\n",
    "print(f\"âœ… Selected Checkpoint: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945fade1",
   "metadata": {},
   "source": [
    "## Section 2: Model Architecture Definitions\n",
    "\n",
    "We need to re-define the model architecture classes here because PyTorch requires them when loading the checkpoint.\n",
    "\n",
    "**Note**: These classes must match EXACTLY what was used during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e711522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model architecture classes defined:\n",
      "   â€¢ SEBlock, Backbone, AAMSoftmax, SpeakerClassifier\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: MODEL ARCHITECTURE DEFINITIONS\n",
    "# ============================================================================\n",
    "# These MUST match the architecture used during training\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n",
    "    def __init__(self, channels: int, reduction: int = 16):\n",
    "        super().__init__()\n",
    "        hidden = max(channels // reduction, 4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, hidden, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, T, F = x.shape\n",
    "        s = x.mean(dim=(2, 3))\n",
    "        w = self.fc(s).view(B, C, 1, 1)\n",
    "        return x * w\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    \"\"\"CNN + RNN backbone for speaker embedding extraction.\"\"\"\n",
    "    def __init__(self, no_mels, embed_dim, rnn_hidden, rnn_layers, bidir):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            SEBlock(32, reduction=8),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            SEBlock(64, reduction=8),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            SEBlock(128, reduction=8),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "\n",
    "        self.rnn_hidden = rnn_hidden\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=128 * (no_mels // 8),\n",
    "            hidden_size=self.rnn_hidden,\n",
    "            num_layers=rnn_layers,\n",
    "            bidirectional=bidir,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "        out_dim = (2 if bidir else 1) * rnn_hidden\n",
    "        self.rnn_ln = nn.LayerNorm(out_dim)\n",
    "\n",
    "        self.att = nn.Sequential(\n",
    "            nn.Linear((2 if bidir else 1)*rnn_hidden, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(out_dim*2, 256),\n",
    "            nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Linear(256, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths=None, mc_dropout=None):\n",
    "        if mc_dropout is None:\n",
    "            mc_dropout = self.training\n",
    "            \n",
    "        h = self.cnn_block(x)\n",
    "        if mc_dropout:\n",
    "            h = F.dropout(h, p=0.3, training=True)\n",
    "            \n",
    "        B, C, T, Fp = h.shape\n",
    "        h = h.permute(0, 2, 1, 3).contiguous().view(B, T, C*Fp)\n",
    "\n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(h, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_out, _ = self.rnn(packed)\n",
    "            rnn_out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "            Tmax = rnn_out.size(1)\n",
    "            mask = torch.arange(Tmax, device=rnn_out.device).unsqueeze(0).expand(B, Tmax) < lengths.unsqueeze(1)\n",
    "        else:\n",
    "            rnn_out, _ = self.rnn(h)\n",
    "            mask = torch.ones(rnn_out.size(0), rnn_out.size(1), dtype=torch.bool, device=rnn_out.device)\n",
    "\n",
    "        if mc_dropout:\n",
    "            rnn_out = F.dropout(rnn_out, p=0.3, training=True)\n",
    "\n",
    "        rnn_out = self.rnn_ln(rnn_out)\n",
    "\n",
    "        a = self.att(rnn_out).squeeze(-1)\n",
    "        a = a.masked_fill(~mask, float('-inf'))\n",
    "        w = torch.softmax(a, dim=1).unsqueeze(-1)\n",
    "\n",
    "        mean = torch.sum(w * rnn_out, dim=1)\n",
    "        var = torch.sum(w * (rnn_out - mean.unsqueeze(1))**2, dim=1)\n",
    "        std = torch.sqrt(var + 1e-5)\n",
    "        stats = torch.cat([mean, std], 1)\n",
    "\n",
    "        if mc_dropout:\n",
    "            stats = F.dropout(stats, p=0.3, training=True)\n",
    "\n",
    "        z = self.proj(stats)\n",
    "        z = F.normalize(z, p=2, dim=1)\n",
    "        return z\n",
    "\n",
    "\n",
    "class AAMSoftmax(nn.Module):\n",
    "    \"\"\"Additive Angular Margin Softmax for training.\"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.20):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, emb, labels):\n",
    "        W = F.normalize(self.weight, dim=1)\n",
    "        cos_theta = emb @ W.T\n",
    "        theta = torch.acos(cos_theta.clamp(-1+1e-7, 1-1e-7))\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "        one_hot = F.one_hot(labels, num_classes=W.size(0)).float()\n",
    "        output = cos_theta * (1 - one_hot) + target_logits * one_hot\n",
    "        return output * self.s\n",
    "\n",
    "\n",
    "class SpeakerClassifier(nn.Module):\n",
    "    \"\"\"Main model combining backbone with AAMSoftmax head.\"\"\"\n",
    "    def __init__(self, backbone, num_speakers, aamsm_scaler, aamsm_margin):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.aamsm = AAMSoftmax(backbone.proj[-1].out_features, num_speakers, aamsm_scaler, aamsm_margin)\n",
    "        self._inference_prepared = False\n",
    "        self.score_alpha = nn.Parameter(torch.tensor(1.0))\n",
    "        self.score_beta = nn.Parameter(torch.tensor(0.0))\n",
    "        self.bank = None\n",
    "        self.inference_threshold = 0.5\n",
    "\n",
    "    def forward(self, x, labels=None, lengths=None):\n",
    "        emb = self.backbone(x, lengths=lengths, mc_dropout=None)\n",
    "        if labels is not None:\n",
    "            logits = self.aamsm(emb, labels)\n",
    "            return logits, emb\n",
    "        else:\n",
    "            return emb\n",
    "\n",
    "    def eval(self):\n",
    "        super().eval()\n",
    "        if not self._inference_prepared:\n",
    "            with torch.no_grad():\n",
    "                self.bank = F.normalize(self.aamsm.weight, dim=1)\n",
    "            self._inference_prepared = True\n",
    "        return self\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed(self, x, lengths=None):\n",
    "        z = self.backbone(x, lengths=lengths)\n",
    "        return F.normalize(z, dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def verify_any(self, x, lengths=None, *, threshold=None, bank=None, return_index=False):\n",
    "        if bank is None:\n",
    "            if self.bank is None:\n",
    "                raise RuntimeError('Bank not built. Call model.eval() first!')\n",
    "            bank = self.bank\n",
    "        bank = F.normalize(bank, dim=1)\n",
    "\n",
    "        probe = self.embed(x, lengths=lengths)\n",
    "        bank = bank.to(probe.device)\n",
    "        sims = probe @ bank.T\n",
    "        scores, idx = sims.max(dim=1)\n",
    "\n",
    "        scores = self.score_alpha * scores + self.score_beta\n",
    "        thr = self.inference_threshold if threshold is None else threshold\n",
    "        decisions = scores >= thr\n",
    "\n",
    "        if return_index:\n",
    "            return decisions, scores, idx\n",
    "        return decisions, scores\n",
    "\n",
    "\n",
    "print(\"âœ… Model architecture classes defined:\")\n",
    "print(\"   â€¢ SEBlock, Backbone, AAMSoftmax, SpeakerClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ba4ec",
   "metadata": {},
   "source": [
    "## Section 3: Data Loader for Test Set\n",
    "\n",
    "Load the test split from the HDF5 dataset using the cached (RAM-based) loader for fast evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37fd1c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š DATASET METADATA\n",
      "======================================================================\n",
      "   Dataset: outputs/logmels_binary_aug_26-01-27_11-49-30.h5\n",
      "   Label Mode: binary\n",
      "   Num Classes: 2\n",
      "   Mel Bands: 64\n",
      "   In-Group Speakers: ['Aleksander', 'Mantas', 'Michal', 'Piotr', 'Rafal']\n",
      "   Out-Group Speakers: ['Adi', 'Churchill', 'FDR', 'AnnaAleksander', 'GrianYT', 'LenaW', 'Szyc', 'JFK', 'KryptydaYT', 'Oppenheimer', 'Oversimplified', 'Pati', 'queenElisabeth', 'Reagan', 'Thatcher', 'trump', 'Bailey', 'HomelessGuy', 'JustExist', 'Kaos', 'KindCowboy', 'OldMan', 'Ponder', 'AnnaMichal', 'WeronikaMichal', 'IwoMichal', 'AlicjaMichal', 'Anne', 'Dominika', 'Emma', 'Greta', 'Julian', 'Lara', 'Marzena', 'Natalia', 'Obama', 'Buffet', 'chaplin', 'gates', 'jbp', 'Kevin', 'Linus', 'Nobel1', 'Malala', 'Theresa', 'Nobel4', 'pacino', 'qba', 'reeves', 'smith', 'sob', 'Torvalds', 'turing']\n",
      "\n",
      "======================================================================\n",
      "ğŸ“¦ LOADING TEST DATA\n",
      "======================================================================\n",
      "âœ“ Remapping 2 labels to dense range 0..1\n",
      "ğŸš€ Loading 20948 samples (test) into RAM...\n",
      "âœ“ TEST: 20948 samples loaded in 1.3s\n",
      "âœ“ Test loader ready: 82 batches\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3: DATA LOADER SETUP\n",
    "# ============================================================================\n",
    "from data_utils import LMDataset, pad_collate\n",
    "from functools import partial\n",
    "\n",
    "class CachedLMDataset(LMDataset):\n",
    "    \"\"\"Fast RAM-cached dataset loader.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        print(f\"ğŸš€ Loading {self.N} samples ({self.split}) into RAM...\")\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        self._ensure_open()\n",
    "        \n",
    "        X_all = np.array(self._X[:], dtype=self.dtype)\n",
    "        Y_all = np.array(self._Y[:]) if self.has_labels else None\n",
    "        L_all = np.array(self._L[:]) if self.has_lengths else None\n",
    "        \n",
    "        if self._h5 is not None:\n",
    "            self._h5.close()\n",
    "            self._h5 = None\n",
    "        \n",
    "        self.cache = []\n",
    "        for idx in range(self.N):\n",
    "            X = X_all[idx]\n",
    "            if X.ndim != 2:\n",
    "                raise ValueError(f\"Expected 2D logmel, got {X.shape}\")\n",
    "            \n",
    "            if self.time_dim == \"F\":\n",
    "                X = X.T\n",
    "            \n",
    "            X = torch.from_numpy(X[None, ...].copy())\n",
    "            \n",
    "            y_raw = Y_all[idx] if Y_all is not None else None\n",
    "            if y_raw is not None and self.label_map is not None:\n",
    "                y_val = self.label_map.get(int(y_raw), int(y_raw))\n",
    "            else:\n",
    "                y_val = int(y_raw) if y_raw is not None else None\n",
    "            y = torch.tensor(y_val, dtype=torch.long) if y_val is not None else None\n",
    "            \n",
    "            t_len = int(L_all[idx]) if L_all is not None else X.shape[1]\n",
    "            t_len = torch.tensor(t_len, dtype=torch.long)\n",
    "            \n",
    "            self.cache.append((X, y, t_len))\n",
    "        \n",
    "        load_time = time.perf_counter() - start_time\n",
    "        print(f\"âœ“ {self.split.upper()}: {self.N} samples loaded in {load_time:.1f}s\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.cache[idx]\n",
    "\n",
    "\n",
    "def build_test_loader(h5_path, batch_size=256, remap_labels=True):\n",
    "    \"\"\"Build test DataLoader only.\"\"\"\n",
    "    \n",
    "    # Label remapping\n",
    "    label_map = None\n",
    "    if remap_labels:\n",
    "        all_labels = set()\n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            for s in f.keys():\n",
    "                if s in [\"train\", \"val\", \"test\"] and \"label\" in f[s]:\n",
    "                    all_labels.update(f[s][\"label\"][:])\n",
    "        sorted_labels = sorted(list(all_labels))\n",
    "        label_map = {old: new for new, old in enumerate(sorted_labels)}\n",
    "        print(f\"âœ“ Remapping {len(label_map)} labels to dense range 0..{len(label_map)-1}\")\n",
    "\n",
    "    # Create cached dataset for test split\n",
    "    dataset = CachedLMDataset(\n",
    "        h5_path=h5_path,\n",
    "        split=\"test\",\n",
    "        feature_key=\"logmel\",\n",
    "        label_key=\"label\",\n",
    "        length_key=\"length\",\n",
    "        time_dim=\"F\",\n",
    "        label_map=label_map,\n",
    "    )\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=partial(pad_collate, pad_value=-80.0),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATASET METADATA\n",
    "# ============================================================================\n",
    "def get_yaml_meta(h5_path):\n",
    "    \"\"\"Read metadata from HDF5 file.\"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        raw = f[\"/meta/file_description.yaml\"][()].decode(\"utf-8\")\n",
    "        meta_yaml = yaml.safe_load(raw) or {}\n",
    "\n",
    "        meta_grp = f[\"/meta\"]\n",
    "        attrs = {k: (int(v) if isinstance(v, (np.integer,)) else v) for k, v in meta_grp.attrs.items()}\n",
    "        meta_yaml.update(attrs)\n",
    "\n",
    "        if \"speaker_mapping.yaml\" in meta_grp:\n",
    "            sm_raw = meta_grp[\"speaker_mapping.yaml\"][()].decode(\"utf-8\")\n",
    "            sm = yaml.safe_load(sm_raw) or {}\n",
    "            meta_yaml[\"speaker_mapping\"] = sm\n",
    "            speakers = sm.get(\"speakers\", {})\n",
    "            meta_yaml[\"total_speakers\"] = len(speakers)\n",
    "            meta_yaml[\"in_group_speakers\"] = sm.get(\"in_group_speakers\", [])\n",
    "            meta_yaml[\"out_group_speakers\"] = sm.get(\"out_group_speakers\", [])\n",
    "\n",
    "    return meta_yaml\n",
    "\n",
    "\n",
    "# Load metadata\n",
    "meta = get_yaml_meta(dataset_path)\n",
    "no_mels = meta[\"preprocessing_config\"][\"n_mels\"]\n",
    "num_classes = meta.get(\"num_classes\", meta[\"total_speakers\"])\n",
    "label_mode = meta.get(\"label_mode\", \"speaker_id\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š DATASET METADATA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Dataset: {dataset_path}\")\n",
    "print(f\"   Label Mode: {label_mode}\")\n",
    "print(f\"   Num Classes: {num_classes}\")\n",
    "print(f\"   Mel Bands: {no_mels}\")\n",
    "\n",
    "if \"speaker_mapping\" in meta:\n",
    "    print(f\"   In-Group Speakers: {meta.get('in_group_speakers', [])}\")\n",
    "    print(f\"   Out-Group Speakers: {meta.get('out_group_speakers', [])}\")\n",
    "\n",
    "# Build test loader\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“¦ LOADING TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "test_loader = build_test_loader(dataset_path, batch_size=256)\n",
    "print(f\"âœ“ Test loader ready: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247a81a",
   "metadata": {},
   "source": [
    "## Section 4: Load Trained Model\n",
    "\n",
    "Load the pre-trained checkpoint and prepare the model for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca7f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸  Device: cuda\n",
      "\n",
      "ğŸ“¥ Loading checkpoint: checkpoints/train42/best_model.pt\n",
      "âœ… Checkpoint loaded successfully!\n",
      "\n",
      "ğŸ“Š Model Parameters: 3,646,403\n",
      "âœ“ Model moved to cuda and set to eval mode\n",
      "âœ“ Speaker bank built from AAMSoftmax weights: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 4: LOAD TRAINED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "\n",
    "# Create model with same architecture as training\n",
    "backbone = Backbone(\n",
    "    no_mels=no_mels, \n",
    "    embed_dim=256, \n",
    "    rnn_hidden=256, \n",
    "    rnn_layers=2, \n",
    "    bidir=True\n",
    ")\n",
    "model = SpeakerClassifier(\n",
    "    backbone, \n",
    "    num_speakers=num_classes, \n",
    "    aamsm_scaler=30.0, \n",
    "    aamsm_margin=0.25\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "print(f\"\\nğŸ“¥ Loading checkpoint: {checkpoint_path}\")\n",
    "try:\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"âœ… Checkpoint loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ERROR: Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"   Please update the 'checkpoint_path' variable above.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"âŒ ERROR loading checkpoint: {e}\")\n",
    "    print(\"   This usually means the model architecture doesn't match the checkpoint.\")\n",
    "\n",
    "# Move to device and set to eval mode\n",
    "model = model.to(device)\n",
    "model.eval()  # This also builds the speaker bank from AAMSoftmax weights\n",
    "\n",
    "# Display model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nğŸ“Š Model Parameters: {total_params:,}\")\n",
    "print(f\"âœ“ Model moved to {device} and set to eval mode\")\n",
    "print(f\"âœ“ Speaker bank built from AAMSoftmax weights: {model.bank.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a41e4a",
   "metadata": {},
   "source": [
    "## Section 5: Evaluation Functions\n",
    "\n",
    "Define comprehensive testing functions for different evaluation modes:\n",
    "- **Speaker Identification**: Which speaker is this?\n",
    "- **Speaker Verification**: Is this person authorized?\n",
    "- **Binary Classification**: In-group vs out-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679146ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation functions defined:\n",
      "   â€¢ test_speaker_identification(model, test_loader, speaker_mapping)\n",
      "   â€¢ test_speaker_verification(model, test_loader, speaker_mapping, threshold)\n",
      "   â€¢ test_threshold_sweep(model, test_loader, speaker_mapping)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 5: EVALUATION FUNCTIONS\n",
    "# ============================================================================\n",
    "# Supports BOTH modes:\n",
    "#   - Binary mode (2 classes): test_binary_classification()\n",
    "#   - Speaker ID mode (N classes): test_speaker_identification(), test_speaker_verification()\n",
    "\n",
    "def _get_device_safe(model, device):\n",
    "    \"\"\"Get device safely without redundant .to() calls.\"\"\"\n",
    "    if device is not None:\n",
    "        return device\n",
    "    try:\n",
    "        return next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def test_binary_classification(model, test_loader, device=None):\n",
    "    \"\"\"\n",
    "    Test model for BINARY classification (outsider=0, group_member=1).\n",
    "    \n",
    "    Use this when LABEL_MODE=\"binary\" in prepare_h5.ipynb.\n",
    "    The model has 2 output classes:\n",
    "        - Class 0 = Outsider (access denied)\n",
    "        - Class 1 = Group member (access granted)\n",
    "    \n",
    "    Returns:\n",
    "        dict with accuracy, precision, recall, f1, confusion matrix, FAR/FRR\n",
    "    \"\"\"\n",
    "    device = _get_device_safe(model, device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X, y, lengths = batch if len(batch) == 3 else (*batch, None)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            if lengths is not None:\n",
    "                lengths = lengths.to(device)\n",
    "            \n",
    "            # Use embed() for inference (no AAMSoftmax margin)\n",
    "            embeddings = model.embed(X, lengths=lengths)\n",
    "            \n",
    "            # Compute logits via cosine similarity to class weights\n",
    "            W = F.normalize(model.aamsm.weight, dim=1)\n",
    "            logits = embeddings @ W.T * model.aamsm.s\n",
    "            \n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy() if probs.size(1) > 1 else probs[:, 0].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"BINARY CLASSIFICATION TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“Š Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Classification Report:\")\n",
    "    target_names = [\"Outsider (0)\", \"Group Member (1)\"]\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nğŸ”¢ Confusion Matrix:\")\n",
    "    print(f\"                  Predicted\")\n",
    "    print(f\"                  Out   In\")\n",
    "    print(f\"  Actual Out  [{cm[0,0]:5d}  {cm[0,1]:5d}]\")\n",
    "    print(f\"  Actual In   [{cm[1,0]:5d}  {cm[1,1]:5d}]\")\n",
    "    \n",
    "    # Calculate access control metrics\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        far = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Acceptance Rate\n",
    "        frr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Rejection Rate\n",
    "        print(f\"\\nğŸ” Access Control Metrics:\")\n",
    "        print(f\"   True Positives (correctly granted):  {tp}\")\n",
    "        print(f\"   True Negatives (correctly denied):   {tn}\")\n",
    "        print(f\"   False Positives (wrongly granted):   {fp}\")\n",
    "        print(f\"   False Negatives (wrongly denied):    {fn}\")\n",
    "        print(f\"\\n   False Acceptance Rate (FAR): {far:.4f} ({far*100:.2f}%)\")\n",
    "        print(f\"   False Rejection Rate (FRR): {frr:.4f} ({frr*100:.2f}%)\")\n",
    "        print(f\"   Equal Error Rate (EER) â‰ˆ: {(far + frr) / 2:.4f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Binary Classification Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"predictions\": all_preds,\n",
    "        \"labels\": all_labels,\n",
    "        \"probabilities\": all_probs,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"far\": far if cm.shape == (2, 2) else None,\n",
    "        \"frr\": frr if cm.shape == (2, 2) else None\n",
    "    }\n",
    "\n",
    "\n",
    "def test_model_auto(model, test_loader, meta,threshold=0.7 ,device=None):\n",
    "    \"\"\"\n",
    "    Automatically choose the right test based on label_mode from metadata.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained SpeakerClassifier\n",
    "        test_loader: DataLoader for test set\n",
    "        meta: Dataset metadata (from get_yaml_meta)\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        dict with test results\n",
    "    \"\"\"\n",
    "    label_mode = meta.get(\"label_mode\", \"speaker_id\")\n",
    "    \n",
    "    print(f\"ğŸ” Detected label_mode: {label_mode}\")\n",
    "    \n",
    "    if label_mode == \"binary\":\n",
    "        print(\"   â†’ Running BINARY classification test\\n\")\n",
    "        return test_binary_classification(model, test_loader, device)\n",
    "    else:\n",
    "        print(\"   â†’ Running SPEAKER ID tests (identification + verification)\\n\")\n",
    "        speaker_mapping = meta.get(\"speaker_mapping\", None)\n",
    "        \n",
    "        # Part 1: Identification\n",
    "        id_results = test_speaker_identification(model, test_loader, speaker_mapping, device)\n",
    "        \n",
    "        # Part 2: Verification (if speaker mapping available)\n",
    "        if speaker_mapping and model.bank is not None:\n",
    "            print(\"\\n\")\n",
    "            ver_results = test_speaker_verification(model, test_loader, speaker_mapping, threshold=0.7, device=device)\n",
    "            return {\"identification\": id_results, \"verification\": ver_results}\n",
    "        \n",
    "        return {\"identification\": id_results}\n",
    "\n",
    "\n",
    "def test_speaker_identification(model, test_loader, speaker_mapping=None, device=None):\n",
    "    \"\"\"\n",
    "    Test SPEAKER IDENTIFICATION (multi-class classification).\n",
    "    \n",
    "    Returns accuracy and per-speaker metrics.\n",
    "    \"\"\"\n",
    "    device = _get_device_safe(model, device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X, y, lengths = batch if len(batch) == 3 else (*batch, None)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            if lengths is not None:\n",
    "                lengths = lengths.to(device)\n",
    "            \n",
    "            # Use embed() for inference (no AAMSoftmax margin)\n",
    "            embeddings = model.embed(X, lengths=lengths)\n",
    "            \n",
    "            # Compute logits via cosine similarity\n",
    "            W = F.normalize(model.aamsm.weight, dim=1)\n",
    "            logits = embeddings @ W.T * model.aamsm.s\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "    \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SPEAKER IDENTIFICATION TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“Š Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    unique_speakers = sorted(set(all_labels))\n",
    "    \n",
    "    if speaker_mapping:\n",
    "        id_to_name = speaker_mapping.get(\"id_to_speaker\", {})\n",
    "        in_group_list = speaker_mapping.get(\"in_group_speakers\", [])\n",
    "    else:\n",
    "        id_to_name = {str(i): f\"Speaker_{i}\" for i in unique_speakers}\n",
    "        in_group_list = []\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ Per-Speaker Accuracy ({len(unique_speakers)} speakers):\")\n",
    "    for spk_id in unique_speakers:\n",
    "        mask = [l == spk_id for l in all_labels]\n",
    "        spk_preds = [p for p, m in zip(all_preds, mask) if m]\n",
    "        spk_labels = [l for l, m in zip(all_labels, mask) if m]\n",
    "        \n",
    "        if len(spk_labels) > 0:\n",
    "            spk_acc = accuracy_score(spk_labels, spk_preds)\n",
    "            name = id_to_name.get(str(spk_id), f\"Speaker_{spk_id}\")\n",
    "            in_group = \"ğŸŸ¢\" if name in in_group_list else \"ğŸ”´\"\n",
    "            print(f\"   {in_group} ID {spk_id:2d} ({name:20s}): {spk_acc:.4f} [{len(spk_labels)} samples]\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[f\"Spk_{i}\" for i in unique_speakers],\n",
    "                yticklabels=[f\"Spk_{i}\" for i in unique_speakers])\n",
    "    plt.xlabel('Predicted Speaker')\n",
    "    plt.ylabel('Actual Speaker')\n",
    "    plt.title('Speaker Identification Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"predictions\": all_preds,\n",
    "        \"labels\": all_labels,\n",
    "        \"embeddings\": all_embeddings,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "\n",
    "def test_speaker_verification(model, test_loader, speaker_mapping, threshold=0.7, device=None):\n",
    "    \"\"\"\n",
    "    Test SPEAKER VERIFICATION with embedding-based access control.\n",
    "    \n",
    "    1. Identify speaker using embeddings\n",
    "    2. Check if identified speaker is in_group\n",
    "    3. Grant/deny access based on threshold\n",
    "    \"\"\"\n",
    "    device = _get_device_safe(model, device)\n",
    "    model.eval()\n",
    "    \n",
    "    if model.bank is None:\n",
    "        print(\"âš ï¸ Model bank not built. Call model.eval() first!\")\n",
    "        return None\n",
    "    \n",
    "    # Get in_group speaker IDs\n",
    "    speakers_info = speaker_mapping.get(\"speakers\", {})\n",
    "    in_group_names = speaker_mapping.get(\"in_group_speakers\", [])\n",
    "    in_group_ids = set()\n",
    "    for name in in_group_names:\n",
    "        if name in speakers_info:\n",
    "            in_group_ids.add(speakers_info[name][\"id\"])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X, y, lengths = batch if len(batch) == 3 else (*batch, None)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            if lengths is not None:\n",
    "                lengths = lengths.to(device)\n",
    "            \n",
    "            decisions, scores, pred_ids = model.verify_any(\n",
    "                X, lengths=lengths, threshold=threshold, return_index=True\n",
    "            )\n",
    "            \n",
    "            for i in range(X.size(0)):\n",
    "                true_label = y[i].item()\n",
    "                pred_id = pred_ids[i].item()\n",
    "                score = scores[i].item()\n",
    "                decision = decisions[i].item()\n",
    "                \n",
    "                true_in_group = true_label in in_group_ids\n",
    "                pred_in_group = decision and (pred_id in in_group_ids)\n",
    "                \n",
    "                results.append({\n",
    "                    \"true_speaker\": true_label,\n",
    "                    \"pred_speaker\": pred_id,\n",
    "                    \"speaker_correct\": true_label == pred_id,\n",
    "                    \"score\": score,\n",
    "                    \"decision\": decision,\n",
    "                    \"true_in_group\": true_in_group,\n",
    "                    \"pred_in_group\": pred_in_group,\n",
    "                    \"access_correct\": true_in_group == pred_in_group\n",
    "                })\n",
    "    \n",
    "    # Calculate metrics\n",
    "    n_samples = len(results)\n",
    "    speaker_acc = sum(r[\"speaker_correct\"] for r in results) / n_samples\n",
    "    access_acc = sum(r[\"access_correct\"] for r in results) / n_samples\n",
    "    \n",
    "    tp = sum(1 for r in results if r[\"true_in_group\"] and r[\"pred_in_group\"])\n",
    "    tn = sum(1 for r in results if not r[\"true_in_group\"] and not r[\"pred_in_group\"])\n",
    "    fp = sum(1 for r in results if not r[\"true_in_group\"] and r[\"pred_in_group\"])\n",
    "    fn = sum(1 for r in results if r[\"true_in_group\"] and not r[\"pred_in_group\"])\n",
    "    \n",
    "    far = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    frr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"SPEAKER VERIFICATION TEST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ¯ Verification Threshold: {threshold}\")\n",
    "    print(f\"\\nğŸ“Š Speaker Identification Accuracy: {speaker_acc:.4f} ({speaker_acc*100:.2f}%)\")\n",
    "    print(f\"ğŸ“Š Access Control Accuracy: {access_acc:.4f} ({access_acc*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ” Access Control Confusion Matrix:\")\n",
    "    print(f\"                      Predicted Access\")\n",
    "    print(f\"                      Deny    Grant\")\n",
    "    print(f\"  Actual Outsider  [{tn:6d}  {fp:6d}]\")\n",
    "    print(f\"  Actual Member    [{fn:6d}  {tp:6d}]\")\n",
    "    \n",
    "    print(f\"\\nğŸ” Access Control Metrics:\")\n",
    "    print(f\"   True Positives (correctly granted): {tp}\")\n",
    "    print(f\"   True Negatives (correctly denied):  {tn}\")\n",
    "    print(f\"   False Positives (wrongly granted):  {fp}\")\n",
    "    print(f\"   False Negatives (wrongly denied):   {fn}\")\n",
    "    print(f\"\\n   False Acceptance Rate (FAR): {far:.4f} ({far*100:.2f}%)\")\n",
    "    print(f\"   False Rejection Rate (FRR): {frr:.4f} ({frr*100:.2f}%)\")\n",
    "    print(f\"   Equal Error Rate (EER) â‰ˆ: {(far + frr) / 2:.4f}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        \"speaker_accuracy\": speaker_acc,\n",
    "        \"access_accuracy\": access_acc,\n",
    "        \"threshold\": threshold,\n",
    "        \"far\": far, \"frr\": frr,\n",
    "        \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "\n",
    "def test_threshold_sweep(model, test_loader, speaker_mapping, thresholds=None, device=None):\n",
    "    \"\"\"\n",
    "    Test multiple thresholds to find optimal operating point.\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    \n",
    "    results = []\n",
    "    for thr in thresholds:\n",
    "        res = test_speaker_verification(model, test_loader, speaker_mapping, \n",
    "                                         threshold=thr, device=device)\n",
    "        if res:\n",
    "            results.append({\n",
    "                \"threshold\": thr,\n",
    "                \"far\": res[\"far\"],\n",
    "                \"frr\": res[\"frr\"],\n",
    "                \"access_accuracy\": res[\"access_accuracy\"]\n",
    "            })\n",
    "    \n",
    "    # Plot FAR/FRR trade-off\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    thrs = [r[\"threshold\"] for r in results]\n",
    "    fars = [r[\"far\"] for r in results]\n",
    "    frrs = [r[\"frr\"] for r in results]\n",
    "    \n",
    "    plt.plot(thrs, fars, 'b-', label='FAR (False Accept)', linewidth=2)\n",
    "    plt.plot(thrs, frrs, 'r-', label='FRR (False Reject)', linewidth=2)\n",
    "    \n",
    "    # Find EER\n",
    "    eer_idx = np.argmin(np.abs(np.array(fars) - np.array(frrs)))\n",
    "    eer_thr = thrs[eer_idx]\n",
    "    eer_val = (fars[eer_idx] + frrs[eer_idx]) / 2\n",
    "    plt.axvline(x=eer_thr, color='green', linestyle='--', label=f'EER @ {eer_thr:.2f}')\n",
    "    \n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('FAR/FRR Trade-off Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ“ Optimal EER threshold: {eer_thr:.2f} (EER â‰ˆ {eer_val:.4f})\")\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"âœ… Evaluation functions defined:\")\n",
    "print(\"   â€¢ test_speaker_identification(model, test_loader, speaker_mapping)\")\n",
    "print(\"   â€¢ test_speaker_verification(model, test_loader, speaker_mapping, threshold)\")\n",
    "print(\"   â€¢ test_threshold_sweep(model, test_loader, speaker_mapping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954fa7a",
   "metadata": {},
   "source": [
    "## Section 6: Run Evaluation\n",
    "\n",
    "Execute the evaluation tests on the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77eaeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ§ª RUNNING MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ Detected label_mode: 'binary'\n",
      "--------------------------------------------------\n",
      "ğŸ” Detected label_mode: binary\n",
      "   â†’ Running BINARY classification test\n",
      "\n",
      "======================================================================\n",
      "BINARY CLASSIFICATION TEST RESULTS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Overall Accuracy: 0.9914 (99.14%)\n",
      "\n",
      "ğŸ“‹ Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Outsider (0)     0.9929    0.9971    0.9950     17856\n",
      "Group Member (1)     0.9828    0.9586    0.9705      3092\n",
      "\n",
      "        accuracy                         0.9914     20948\n",
      "       macro avg     0.9878    0.9778    0.9828     20948\n",
      "    weighted avg     0.9914    0.9914    0.9914     20948\n",
      "\n",
      "\n",
      "ğŸ”¢ Confusion Matrix:\n",
      "                  Predicted\n",
      "                  Out   In\n",
      "  Actual Out  [17804     52]\n",
      "  Actual In   [  128   2964]\n",
      "\n",
      "ğŸ” Access Control Metrics:\n",
      "   True Positives (correctly granted):  2964\n",
      "   True Negatives (correctly denied):   17804\n",
      "   False Positives (wrongly granted):   52\n",
      "   False Negatives (wrongly denied):    128\n",
      "\n",
      "   False Acceptance Rate (FAR): 0.0029 (0.29%)\n",
      "   False Rejection Rate (FRR): 0.0414 (4.14%)\n",
      "   Equal Error Rate (EER) â‰ˆ: 0.0222\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6: RUN EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ§ª RUNNING MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Auto-detect mode and run appropriate tests\n",
    "label_mode = meta.get(\"label_mode\", \"speaker\")\n",
    "print(f\"\\nğŸ“‹ Detected label_mode: '{label_mode}'\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "results = test_model_auto(\n",
    "    model,\n",
    "    test_loader,\n",
    "    meta=meta,\n",
    "    threshold=0.7,  # Adjust as needed\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46430387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ PART 2: Speaker Verification (Access Control)\n",
      "--------------------------------------------------\n",
      "â„¹ï¸ Binary mode detected - verification already tested above\n",
      "   (Binary classification IS the access control decision)\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Speaker Verification / Access Control (for speaker mode only)\n",
    "print(\"\\nğŸ“‹ PART 2: Speaker Verification (Access Control)\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "label_mode = meta.get(\"label_mode\", \"speaker\")\n",
    "\n",
    "if label_mode == \"binary\":\n",
    "    print(\"â„¹ï¸ Binary mode detected - verification already tested above\")\n",
    "    print(\"   (Binary classification IS the access control decision)\")\n",
    "elif \"speaker_mapping\" in meta:\n",
    "    ver_results = test_speaker_verification(\n",
    "        model, \n",
    "        test_loader, \n",
    "        speaker_mapping=meta[\"speaker_mapping\"],\n",
    "        threshold=0.7,  # Adjust this threshold as needed\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    print(\"âš ï¸ No speaker_mapping in metadata - skipping verification test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b965b80",
   "metadata": {},
   "source": [
    "## Section 7: Threshold Optimization (Optional)\n",
    "\n",
    "Sweep through different thresholds to find the optimal operating point (EER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f73b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7: THRESHOLD OPTIMIZATION (OPTIONAL)\n",
    "# ============================================================================\n",
    "# Uncomment and run this cell to find the optimal threshold\n",
    "\n",
    "# print(\"\\nğŸ“‹ PART 3: Threshold Sweep\")\n",
    "# print(\"-\"*50)\n",
    "# \n",
    "# if \"speaker_mapping\" in meta:\n",
    "#     sweep_results = test_threshold_sweep(\n",
    "#         model, \n",
    "#         test_loader, \n",
    "#         speaker_mapping=meta[\"speaker_mapping\"],\n",
    "#         thresholds=np.arange(0.3, 0.95, 0.05),\n",
    "#         device=device\n",
    "#     )\n",
    "# else:\n",
    "#     print(\"âš ï¸ No speaker_mapping in metadata - skipping threshold sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17a0ec",
   "metadata": {},
   "source": [
    "## ğŸ“š Summary\n",
    "\n",
    "### Supported Modes:\n",
    "\n",
    "| Mode | Description | Classes |\n",
    "|------|-------------|---------|\n",
    "| **Binary** (`label_mode='binary'`) | Group member vs Outsider classification | 2 (outsider=0, member=1) |\n",
    "| **Speaker ID** (`label_mode='speaker'`) | Individual speaker identification | N (one per speaker) |\n",
    "\n",
    "### Evaluation Metrics Explained:\n",
    "\n",
    "| Metric | Description |\n",
    "|--------|-------------|\n",
    "| **Speaker Identification Accuracy** | How often the model correctly identifies which speaker is talking |\n",
    "| **Binary Classification Accuracy** | How often the model correctly classifies member vs outsider |\n",
    "| **Access Control Accuracy** | How often the model correctly grants/denies access |\n",
    "| **FAR (False Acceptance Rate)** | % of outsiders wrongly granted access (security risk) |\n",
    "| **FRR (False Rejection Rate)** | % of authorized users wrongly denied access (usability issue) |\n",
    "| **EER (Equal Error Rate)** | Threshold where FAR = FRR (lower is better) |\n",
    "\n",
    "### Threshold Trade-off (Speaker ID mode):\n",
    "- **Higher threshold** â†’ Lower FAR (more secure), Higher FRR (more rejections)\n",
    "- **Lower threshold** â†’ Higher FAR (less secure), Lower FRR (fewer rejections)\n",
    "- **Optimal**: Find the EER point or tune based on your security requirements\n",
    "\n",
    "### Next Steps:\n",
    "1. **If FRR is too high**: Lower the threshold or collect more training data for in-group speakers\n",
    "2. **If FAR is too high**: Raise the threshold or add more diverse out-group speakers to training\n",
    "3. **Export for deployment**: Use `export_onnx.ipynb` to export the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
